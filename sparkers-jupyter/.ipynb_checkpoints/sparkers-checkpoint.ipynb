{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We start by creating the spark session and adding the Scala Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports \n",
    "\n",
    "Some necessary and useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $file.common\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.types._, func._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.{StringType, StructField, StructType, _}\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "import spark.implicits._\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "\n",
    "We define global variables that in the SBT project will be passed as arguments, here as a case study we will asume them since the beggining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var NMATCHES = 10\n",
    "val ACCOUNT_ID = \"639740\" //Global variable in case the account ID should be passed as an argument\n",
    "val URL_PLAYER = \"https://api.opendota.com/api/players/\" ++ ACCOUNT_ID ++ \"/recentMatches\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract\n",
    "\n",
    "We call the API endpoint with Scala IO methods. It is the simplest way to access the data as no api keys are needed. and we directly convert the data to a DataFrame to work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUrlContentJson(url: String): DataFrame = {\n",
    "    val result = scala.io.Source.fromURL(url).mkString\n",
    "    val jsonResponseOneLine = result.toString().stripLineEnd\n",
    "    val jsonRdd = spark.sparkContext.parallelize(jsonResponseOneLine :: Nil)\n",
    "    spark.read.json(jsonRdd)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "Different functions are developed here to calculate the KPIs as asked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function will return a list of strings with all the matches IDs from a player, so that we can later on build a Dataframe joining the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Gets all matches from a player and transforms them to a List of match IDs\n",
    "  def getPlayerMatches(userDF: DataFrame ,nMatches: Int): List[String] = {\n",
    "    userDF.limit(nMatches).select(\"match_id\").rdd.map(r => r(0).toString).collect.toList\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following functions computes the KDAs from a player, being the average, the maximum and the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def avgKdaComputation(userDF: DataFrame, nMatches: Int): Float = {\n",
    "    userDF\n",
    "      .limit(nMatches)\n",
    "      .select(\n",
    "        $\"kills\" + $\"assists\" as \"KA\",\n",
    "        $\"deaths\")\n",
    "      .select($\"KA\" / $\"deaths\" as \"KDA\")\n",
    "      .agg(mean(\"KDA\"))\n",
    "      .withColumn(\"avg(KDA)\", round($\"avg(KDA)\", 2))\n",
    "      .first()\n",
    "      .getDouble(0)\n",
    "      .toFloat\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxKdaComputation(userDF: DataFrame, nMatches: Int): Float = {\n",
    "    userDF\n",
    "      .limit(nMatches)\n",
    "      .select(\n",
    "        $\"kills\" + $\"assists\" as \"KA\",\n",
    "        $\"deaths\")\n",
    "      .select($\"KA\" / $\"deaths\" as \"KDA\")\n",
    "      .orderBy($\"KDA\".desc)\n",
    "      .withColumn(\"KDA\", round($\"KDA\",2))\n",
    "      .first()\n",
    "      .getDouble(0).toFloat\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minKdaComputation(userDF: DataFrame, nMatches: Int): Float = {\n",
    "    userDF\n",
    "      .limit(nMatches)\n",
    "      .select(\n",
    "        $\"kills\" + $\"assists\" as \"KA\",\n",
    "        $\"deaths\")\n",
    "      .select($\"KA\" / $\"deaths\" as \"KDA\")\n",
    "      .orderBy($\"KDA\".asc)\n",
    "      .withColumn(\"KDA\", round($\"KDA\",2))\n",
    "      .first()\n",
    "      .getDouble(0).toFloat\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function computes the KP for one specific match taking into consideration what team the player is playing in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Computes the KP for one specific match depending on the team whether DIRE or RADIANT\n",
    "  def KPComputationTeam(matchDF: DataFrame, userDF: DataFrame): Float = {\n",
    "    matchDF.join(userDF, \"match_id\")\n",
    "      .select($\"kills\", $\"assists\", $\"player_slot\", $\"radiant_score\", $\"dire_score\")\n",
    "      .withColumn(\"player_slot\",\n",
    "        when(col(\"player_slot\") <= 127, (($\"kills\" + $\"assists\") / ($\"radiant_score\")) * 100)\n",
    "          .otherwise((($\"kills\" + $\"assists\") / ($\"dire_score\"))*100)).as(\"KP\")\n",
    "      .withColumn(\"player_slot\",round($\"player_slot\",2))\n",
    "      .select(\"player_slot\").first().getDouble(0).toFloat\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This recursive function takes the results from the previous one, and creates a list of all the KPs from a player, to be evaluated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KPTotalComputation(matchesList: List[String], userDF: DataFrame): List[Float] =\n",
    "    matchesList match {\n",
    "      case Nil => List()\n",
    "      case match_id :: rest =>\n",
    "        val dotaMatchDF = GetUrlContentJson(\"https://api.opendota.com/api/matches/\" ++ match_id)\n",
    "        List(KPComputationTeam(dotaMatchDF, userDF)) ++ KPTotalComputation(rest, userDF)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following functions will recibe the list created before and compute the average, maximum and minimum from the previous list of KPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KPAvg(KPList: List[Float]): Float = {\n",
    "    val x = (KPList.sum / KPList.size)\n",
    "    BigDecimal.decimal(x).setScale(2, BigDecimal.RoundingMode.HALF_UP).toFloat\n",
    "  }\n",
    "\n",
    "  def KPMax(KPList: List[Float]): Float = {\n",
    "    KPList.max\n",
    "  }\n",
    "\n",
    "  def KPMin(KPList: List[Float]): Float = {\n",
    "    KPList.min\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally we create the final DataFrame with the Data that is relevant from this assignment, the structure and schema is custom made so it can be serialized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createKPIdataframe(game: String, player_name: String,total_games: Int, KDAavg : Float,\n",
    "                         KDAmax : Float, KDAmin : Float, KPavg : Float, KPmax : Float, KPmin : Float) : DataFrame  = {\n",
    "\n",
    "    val KPIs = List(Row(game,player_name,total_games,KDAavg,KDAmax,KDAmin,KPavg,KPmax,KPmin))\n",
    "\n",
    "    val schema = StructType(List(\n",
    "      StructField(\"game\", StringType, true ).withComment(\"The title of the game the matches are related to\"),\n",
    "      StructField(\"player_name\", StringType, true).withComment(\"The player’s ingame name / Summoner’s name\"),\n",
    "      StructField(\"total_games\", IntegerType,true),\n",
    "      StructField(\"max_kda\", FloatType, true).withComment(\"Maximum KDA across n games\"),\n",
    "      StructField(\"min_kda\", FloatType,true).withComment(\"Minimum KDA across n games\"),\n",
    "      StructField(\"avg_kda\", FloatType,true).withComment(\"Average KDA across n games\"),\n",
    "      StructField(\"max_kp\", FloatType, true).withComment(\"Maximum KP across n games\"),\n",
    "      StructField(\"min_kp\", FloatType,true).withComment(\"Minimum KP across n games\"),\n",
    "      StructField(\"avg_kp\", FloatType,true).withComment(\"Average KP across n games\")\n",
    "    ))\n",
    "\n",
    "    val rdd = spark.sparkContext.parallelize(KPIs)\n",
    "    spark.createDataFrame(rdd,schema)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load\n",
    "\n",
    "#### Finally we save our data as a JSON file indicating the URL, so that it can be pushed maybe to some cloud service, like S3 or other one. For this case will be saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDFtoJSON(df : DataFrame, url : String) : Unit = {\n",
    "    df.coalesce(1).write.mode(SaveMode.Overwrite).json(url)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dotaPlayerDF = GetUrlContentJson(URL_PLAYER)\n",
    "val playerMatches = getPlayerMatches(dotaPlayerDF, NMATCHES)\n",
    "\n",
    "  //Transform the Data and compute the KPIs\n",
    "  val totalKP = KPTotalComputation(playerMatches, dotaPlayerDF)\n",
    "\n",
    "  val maxKDA = maxKdaComputation(dotaPlayerDF, NMATCHES)\n",
    "  val minKDA = minKdaComputation(dotaPlayerDF, NMATCHES)\n",
    "  val avgKDA = avgKdaComputation(dotaPlayerDF, NMATCHES)\n",
    "\n",
    "  val maxKP = KPMax(totalKP)\n",
    "  val minKP = KPMin(totalKP)\n",
    "  val avgKP = KPAvg(totalKP)\n",
    "\n",
    "  val finalDF = createKPIdataframe(\"Dota\",\"YrikGood\",NMATCHES,maxKDA,minKDA,avgKDA,maxKP,minKP,avgKP)\n",
    "\n",
    "  finalDF.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
